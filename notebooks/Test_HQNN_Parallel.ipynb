{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T16:51:21.873924Z",
     "start_time": "2025-04-04T16:51:19.353929Z"
    }
   },
   "source": [
    "import torch\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from loguru import logger\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='IPython')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "logger.info(f\"Current directory: {os.getcwd()}\")\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.nn.encodings.pennylane_templates import angle_embedding, amplitude_embedding, QAOA_embedding\n",
    "from src.nn.encodings.IQP_embedding import custom_iqp_embedding\n",
    "from src.nn.encodings.NQE_embedding import NQE_embedding\n",
    "from src.nn.encodings.ring_embedding import ring_embedding\n",
    "from src.nn.encodings.waterfall_embedding import waterfall_embedding\n",
    "\n",
    "from src.nn.ansatz.no_entanglement_circuit import no_entanglement_random_circuit\n",
    "from src.nn.ansatz.full_entanglement_circuit import full_entanglement_circuit\n",
    "from src.nn.ansatz.NQ_circuit import NQ_circuit\n",
    "from src.nn.ansatz.ring_circuit import ring_circuit\n",
    "\n",
    "from src.nn.measurements.default import default_measurement\n",
    "\n",
    "from src.nn.models.hybrid.HQNN_Parallel import HQNN_Parallel\n",
    "from src.utils.training import Trainer\n",
    "from src.utils.dataset import load_dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-04-04 18:51:20.604\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m12\u001B[0m - \u001B[1mCurrent directory: /Users/uribagi/Documents/GitHub/QML-Satellite-Image-Classification/notebooks\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define embeddings"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T16:51:21.879750Z",
     "start_time": "2025-04-04T16:51:21.876992Z"
    }
   },
   "source": [
    "def build_embedding_configurations():\n",
    "    \"\"\"\n",
    "    Dynamically create a list of embedding configurations based on parameter sweeps.\n",
    "    \"\"\"\n",
    "    embedding_configurations = []\n",
    "\n",
    "    # ----- Ring Embedding\n",
    "    for n_repeats in [2]:\n",
    "        embedding_configurations.append({\n",
    "            \"name\": \"ring\",\n",
    "            \"func\": ring_embedding,\n",
    "            \"func_params\": {\n",
    "                \"n_repeats\": n_repeats\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # ----- Waterfall Embedding\n",
    "    embedding_configurations.append({\n",
    "        \"name\": \"waterfall\",\n",
    "        \"func\": waterfall_embedding,\n",
    "        \"func_params\": {\n",
    "            \"weights\": None\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # ----- Amplitude Embedding\n",
    "    \"\"\"embedding_configurations.append({\n",
    "        \"name\": \"amplitude\",\n",
    "        \"func\": amplitude_embedding,\n",
    "        \"func_params\": {\n",
    "            \"normalize\": True,\n",
    "            \"pad_with\": 0.0,\n",
    "        }\n",
    "    })\"\"\"\n",
    "\n",
    "    # ----- Angle Embedding\n",
    "    for rotation in [\"X\", \"Y\", \"Z\"]:\n",
    "        embedding_configurations.append({\n",
    "            \"name\": f\"angle_{rotation}\",\n",
    "            \"func\": angle_embedding,\n",
    "            \"func_params\": {\n",
    "                \"rotation\": rotation\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # ----- IQP Embedding\n",
    "    for repeats in [2]:\n",
    "        embedding_configurations.append({\n",
    "            \"name\": f\"iqp_{repeats}\",\n",
    "            \"func\": custom_iqp_embedding,\n",
    "            \"func_params\": {\n",
    "                \"n_repeats\": repeats,\n",
    "                \"pattern\": None\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # ----- NQE Embedding\n",
    "    for repeats in [2]:\n",
    "        embedding_configurations.append({\n",
    "            \"name\": f\"nqe_{repeats}\",\n",
    "            \"func\": NQE_embedding,\n",
    "            \"func_params\": {\n",
    "                \"n_repeats\": repeats\n",
    "            }\n",
    "        })\n",
    "\n",
    "    # ----- QAOA Embedding\n",
    "    for local_field in [\"X\", \"Y\", \"Z\"]:\n",
    "        for n_layers in [2]:\n",
    "            embedding_configurations.append({\n",
    "                \"name\": f\"qaoa_{local_field}_{n_layers}\",\n",
    "                \"func\": QAOA_embedding,\n",
    "                \"func_params\": {\n",
    "                    \"weights\": None,\n",
    "                    \"local_field\": local_field,\n",
    "                    \"n_layers\": n_layers\n",
    "                }\n",
    "            })\n",
    "\n",
    "\n",
    "\n",
    "    return embedding_configurations"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define circuits"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T16:51:21.928470Z",
     "start_time": "2025-04-04T16:51:21.925945Z"
    }
   },
   "source": [
    "def build_circuit_configurations():\n",
    "    num_layers = 2\n",
    "    num_qubits_per_circuit = 8\n",
    "    weights_strongly_entangled = torch.rand(num_layers, num_qubits_per_circuit, 3)% np.pi\n",
    "    weights_nq = torch.rand(3 * 8, 2) % np.pi\n",
    "    weights_no_ent = torch.rand(num_qubits_per_circuit, )  % np.pi\n",
    "\n",
    "    configs = [{\n",
    "        \"name\": f\"no_entanglement\",\n",
    "        \"func\": no_entanglement_random_circuit,\n",
    "        \"func_params\": {\n",
    "            \"num_layers\": 1,\n",
    "            \"weights\": weights_no_ent,\n",
    "            \"weight_shapes\": {\"weights\": (num_qubits_per_circuit)},\n",
    "        }\n",
    "    }, {\n",
    "        \"name\": f\"full_entanglement\",\n",
    "        \"func\": full_entanglement_circuit,\n",
    "        \"func_params\": {\n",
    "            \"num_layers\": num_layers,\n",
    "            \"weights\": weights_strongly_entangled,\n",
    "            \"weight_shapes\": {\"weights\": (num_layers, num_qubits_per_circuit, 3)},\n",
    "        }\n",
    "    },{\n",
    "        \"name\": f\"nq_circuit\",\n",
    "        \"func\": NQ_circuit,\n",
    "        \"func_params\": {\n",
    "            \"weights\": weights_nq,\n",
    "            \"weight_shapes\": {\"weights\": (3* 8, 2)},\n",
    "        }\n",
    "    },\n",
    "        {\n",
    "        \"name\": f\"ring_circuit\",\n",
    "        \"func\": ring_circuit,\n",
    "        \"func_params\": {\n",
    "            \"weights\": weights_nq,\n",
    "            \"weight_shapes\": {\"weights\": (3* num_qubits_per_circuit, 2)},\n",
    "        }\n",
    "    }]\n",
    "\n",
    "    # Full Entanglement\n",
    "    # NQ circuit\n",
    "    # Ring circuit\n",
    "    return configs"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define measurements"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T16:51:21.933578Z",
     "start_time": "2025-04-04T16:51:21.931927Z"
    }
   },
   "source": [
    "measurement_configurations = [\n",
    "    {\n",
    "        \"name\": \"defaultZ\",\n",
    "        \"func\": default_measurement,\n",
    "        \"func_params\": {\"observable\": qml.PauliZ}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"defaultX\",\n",
    "        \"func\": default_measurement,\n",
    "        \"func_params\": {\"observable\": qml.PauliX}\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"defaultY\",\n",
    "        \"func\": default_measurement,\n",
    "        \"func_params\": {\"observable\": qml.PauliY}\n",
    "    }\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T16:51:21.938586Z",
     "start_time": "2025-04-04T16:51:21.936918Z"
    }
   },
   "source": [
    "dataset_configurations = [\n",
    "    {\n",
    "        \"dataset_name\": \"EuroSAT\",\n",
    "        \"limit\": 500,\n",
    "        \"image_size\": 32,\n",
    "        \"test_size\": 0.2,\n",
    "        \"output\": \"np\",\n",
    "        \"allowed_classes\": [\n",
    "            'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',\n",
    "            'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"dataset_name\": \"EuroSAT\",\n",
    "        \"limit\": 500,\n",
    "        \"image_size\": 16,\n",
    "        \"test_size\": 0.2,\n",
    "        \"output\": \"np\",\n",
    "        \"allowed_classes\": [\n",
    "            'AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',\n",
    "            'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake'\n",
    "        ]\n",
    "    }\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T16:51:21.943689Z",
     "start_time": "2025-04-04T16:51:21.941956Z"
    }
   },
   "source": [
    "hyperparameter_configurations = [\n",
    "    {\n",
    "        \"epochs\": 30,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"early_stopping\": True,\n",
    "        \"patience\": 10,\n",
    "        \"use_schedulefree\": True,\n",
    "        \"use_quantum\": False,\n",
    "        \"plot\": False,\n",
    "        \"log_mlflow\": True\n",
    "    },\n",
    "    {\n",
    "        \"epochs\": 30,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"early_stopping\": True,\n",
    "        \"patience\": 10,\n",
    "        \"use_schedulefree\": True,\n",
    "        \"use_quantum\": True,\n",
    "        \"plot\": False,\n",
    "        \"log_mlflow\": True\n",
    "    }\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper function"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-04T16:51:21.954297Z",
     "start_time": "2025-04-04T16:51:21.949899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_experiment(\n",
    "    dataset_cfg,\n",
    "    embedding_cfg,\n",
    "    circuit_cfg,\n",
    "    measurement_cfg,\n",
    "    hparams\n",
    "):\n",
    "    \"\"\"\n",
    "    Prepare data, create model, trainer, and run training for one combination of config.\n",
    "    \"\"\"\n",
    "    # Unpack dataset settings\n",
    "    dataset_name = dataset_cfg[\"dataset_name\"]\n",
    "    limit = dataset_cfg[\"limit\"]\n",
    "    image_size = dataset_cfg[\"image_size\"]\n",
    "    test_size = dataset_cfg[\"test_size\"]\n",
    "    output = dataset_cfg[\"output\"]\n",
    "    allowed_classes = dataset_cfg[\"allowed_classes\"]\n",
    "    n_classes = len(allowed_classes)\n",
    "\n",
    "    # Unpack hyperparameters\n",
    "    epochs = hparams[\"epochs\"]\n",
    "    lr = hparams[\"learning_rate\"]\n",
    "    early_stopping = hparams[\"early_stopping\"]\n",
    "    patience = hparams[\"patience\"]\n",
    "    use_schedulefree = hparams[\"use_schedulefree\"]\n",
    "    use_quantum = hparams[\"use_quantum\"]\n",
    "    plot = hparams[\"plot\"]\n",
    "    log_mlflow = hparams[\"log_mlflow\"]\n",
    "\n",
    "    # The circuit dictionary also includes the chosen qkernel_shape\n",
    "    if use_quantum:\n",
    "        # Loguru info: Start of run\n",
    "        logger.info(f\"Starting run: dataset={dataset_name}, \"\n",
    "                f\"embedding={embedding_cfg['name']}, \"\n",
    "                f\"circuit={circuit_cfg['name']}, measurement={measurement_cfg['name']}, \"\n",
    "                f\"epochs={epochs}, lr={lr}\")\n",
    "\n",
    "        run_name = (\n",
    "            f\"HQNN_Parallel_{dataset_name}_{image_size}x{image_size}_\"\n",
    "            f\"emb={embedding_cfg['name']}_circuit={circuit_cfg['name']}_meas={measurement_cfg['name']}_\"\n",
    "            f\"lr={lr}_ep={epochs}\"\n",
    "        )\n",
    "    # Create a dictionary of all configurations for MLflow\n",
    "        mlflow_params = {\n",
    "            # Dataset parameters\n",
    "            \"dataset_name\": dataset_name,\n",
    "            \"limit\": limit,\n",
    "            \"image_size\": image_size,\n",
    "            \"test_size\": test_size,\n",
    "            \"allowed_classes\": str(allowed_classes),  # Convert list to string\n",
    "\n",
    "            # Embedding parameters\n",
    "            \"embedding_name\": embedding_cfg['name'],\n",
    "\n",
    "            # Circuit parameters\n",
    "            \"circuit_name\": circuit_cfg['name'],\n",
    "\n",
    "            # Measurement parameters\n",
    "            \"measurement_name\": measurement_cfg['name'],\n",
    "\n",
    "            # Any other relevant parameters you want to track\n",
    "            \"run_timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        }\n",
    "\n",
    "        embedding_params={\n",
    "            \"func\": embedding_cfg[\"func\"],\n",
    "            \"func_params\": embedding_cfg[\"func_params\"]\n",
    "        }\n",
    "\n",
    "        variational_params={\n",
    "                \"func\": circuit_cfg[\"func\"],\n",
    "                \"func_params\": circuit_cfg[\"func_params\"]  # includes 'weights' re-init\n",
    "            }\n",
    "        measurement_params={\n",
    "            \"func\": measurement_cfg[\"func\"],\n",
    "            \"func_params\": measurement_cfg[\"func_params\"]\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        logger.info(f\"Starting Classic run: dataset={dataset_name}, \"\n",
    "                f\"epochs={epochs}, lr={lr}\")\n",
    "\n",
    "        run_name = (\n",
    "            f\"HQNN_Parallel_{dataset_name}_{image_size}x{image_size}_\"\n",
    "            f\"classic_\"\n",
    "            f\"lr={lr}_ep={epochs}\"\n",
    "        )\n",
    "        mlflow_params = {}\n",
    "        embedding_params={}\n",
    "        variational_params={}\n",
    "        measurement_params={}\n",
    "\n",
    "    mlflow_project_name = f\"{dataset_name} {image_size}x{image_size}\"\n",
    "\n",
    "    # 1. Load Dataset\n",
    "    train_loader, val_loader = load_dataset(\n",
    "        dataset_name,\n",
    "        output,\n",
    "        limit,\n",
    "        allowed_classes,\n",
    "        image_size,\n",
    "        test_size,\n",
    "    )\n",
    "\n",
    "    # 2. Create model\n",
    "    model = HQNN_Parallel(\n",
    "        embedding_params=embedding_params,\n",
    "        variational_params=variational_params,\n",
    "        measurement_params=measurement_params,\n",
    "        n_classes=n_classes,\n",
    "        use_quantum=use_quantum,\n",
    "        dataset=dataset_name,\n",
    "        input_size=image_size\n",
    "    )\n",
    "\n",
    "    # 3. Create Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=epochs,\n",
    "        early_stopping=early_stopping,\n",
    "        patience=patience,\n",
    "        log=log_mlflow,\n",
    "        mlflow_project=mlflow_project_name,\n",
    "        mlflow_run_name=run_name,\n",
    "        use_quantum=use_quantum,\n",
    "        plot=plot,\n",
    "        allowed_classes=allowed_classes,\n",
    "        lr=lr,\n",
    "        use_schedulefree=use_schedulefree,\n",
    "        mlflow_params=mlflow_params,\n",
    "    )\n",
    "\n",
    "    logger.debug(f\"Trainer created: early_stopping={early_stopping}, \"\n",
    "                 f\"patience={patience}, log_mlflow={log_mlflow}\")\n",
    "\n",
    "    # 4. Train\n",
    "    trainer.fit()\n",
    "\n",
    "    logger.info(f\"Finished run: {run_name}\")"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-04T16:51:21.956685Z"
    }
   },
   "source": [
    "# 1. Build all embedding configs (with angle, iqp, nqe, qaoa sweeps, etc.)\n",
    "dynamic_embedding_configurations = build_embedding_configurations()\n",
    "\n",
    "# 2. Build circuit configs for qkernel_shape in [2,3,5]\n",
    "circuit_configurations = build_circuit_configurations()\n",
    "\n",
    "# 3. Nested loops\n",
    "for hp_cfg in hyperparameter_configurations:\n",
    "    for dataset_cfg in dataset_configurations:\n",
    "        if not hp_cfg[\"use_quantum\"]:\n",
    "            # Run the experiment\n",
    "            run_experiment(\n",
    "                dataset_cfg=dataset_cfg,\n",
    "                embedding_cfg={},\n",
    "                circuit_cfg={},\n",
    "                measurement_cfg={},\n",
    "                hparams=hp_cfg\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        for emb_cfg in dynamic_embedding_configurations:\n",
    "            for cir_cfg in circuit_configurations:\n",
    "                for meas_cfg in measurement_configurations:\n",
    "                    run_experiment(\n",
    "                        dataset_cfg=dataset_cfg,\n",
    "                        embedding_cfg=emb_cfg,\n",
    "                        circuit_cfg=cir_cfg,\n",
    "                        measurement_cfg=meas_cfg,\n",
    "                        hparams=hp_cfg\n",
    "\n",
    "                    )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-04-04 18:51:21.958\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mrun_experiment\u001B[0m:\u001B[36m80\u001B[0m - \u001B[1mStarting Classic run: dataset=EuroSAT, epochs=30, lr=0.01\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:09.647\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mrun_experiment\u001B[0m:\u001B[36m135\u001B[0m - \u001B[34m\u001B[1mTrainer created: early_stopping=True, patience=10, log_mlflow=True\u001B[0m\n",
      "2025/04/04 18:52:09 INFO mlflow.tracking.fluent: Experiment with name 'EuroSAT 32x32' does not exist. Creating a new experiment.\n",
      "\u001B[32m2025-04-04 18:52:10.908\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [1/30]: Train Loss = 1.8738, Train Acc = 31.62%, Val Loss = 1.4565, Val Acc = 46.00%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:11.976\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [2/30]: Train Loss = 1.3460, Train Acc = 52.40%, Val Loss = 1.1318, Val Acc = 57.90%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:13.056\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [3/30]: Train Loss = 1.0718, Train Acc = 61.27%, Val Loss = 0.9960, Val Acc = 64.30%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:14.129\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [4/30]: Train Loss = 0.8866, Train Acc = 66.95%, Val Loss = 0.9243, Val Acc = 66.60%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:15.204\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [5/30]: Train Loss = 0.7287, Train Acc = 72.47%, Val Loss = 0.9132, Val Acc = 68.70%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:16.628\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [6/30]: Train Loss = 0.6030, Train Acc = 77.97%, Val Loss = 0.9775, Val Acc = 69.00%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:17.710\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [7/30]: Train Loss = 0.4696, Train Acc = 82.80%, Val Loss = 1.1069, Val Acc = 69.00%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:18.789\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [8/30]: Train Loss = 0.3557, Train Acc = 87.30%, Val Loss = 1.3375, Val Acc = 67.70%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:19.870\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [9/30]: Train Loss = 0.2839, Train Acc = 89.75%, Val Loss = 1.6537, Val Acc = 66.40%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:20.958\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [10/30]: Train Loss = 0.2535, Train Acc = 91.40%, Val Loss = 1.9040, Val Acc = 66.10%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:22.029\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [11/30]: Train Loss = 0.1666, Train Acc = 94.15%, Val Loss = 2.1519, Val Acc = 66.40%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:23.104\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [12/30]: Train Loss = 0.1532, Train Acc = 95.08%, Val Loss = 2.3789, Val Acc = 66.10%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:24.174\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [13/30]: Train Loss = 0.1710, Train Acc = 94.97%, Val Loss = 2.4204, Val Acc = 67.10%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:25.253\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m226\u001B[0m - \u001B[34m\u001B[1mEpoch [14/30]: Train Loss = 0.1084, Train Acc = 96.47%, Val Loss = 2.5084, Val Acc = 67.10%\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:26.340\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36msrc.utils.training\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m214\u001B[0m - \u001B[1mEarly stopping at epoch 15\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:26.343\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mrun_experiment\u001B[0m:\u001B[36m141\u001B[0m - \u001B[1mFinished run: HQNN_Parallel_EuroSAT_32x32_classic_lr=0.01_ep=30\u001B[0m\n",
      "\u001B[32m2025-04-04 18:52:26.344\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mrun_experiment\u001B[0m:\u001B[36m80\u001B[0m - \u001B[1mStarting Classic run: dataset=EuroSAT, epochs=30, lr=0.01\u001B[0m\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
