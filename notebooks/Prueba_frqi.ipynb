{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc623996-26ae-4e28-97cb-9647a219d6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/user/QML-Satellite-Image-Classification\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "\n",
    "from src.nn.ansatz.simplified_two_design import simplified_two_design, get_num_params_simplified_two_design\n",
    "from src.nn.ansatz.one_kernel import one_kernel, get_num_params_one_kernel\n",
    "from src.nn.ansatz.two_kernels import two_kernels, get_num_params_two_kernels\n",
    "from src.nn.ansatz.no_entanglement_circuit import no_entanglement_random_circuit\n",
    "from src.nn.ansatz.full_entanglement_circuit import full_entanglement_circuit\n",
    "from src.nn.ansatz.conv_ansatz import QCNN_multiclass, get_num_params_QCNN_multiclass\n",
    "from src.nn.measurements.default import default_measurement\n",
    "from src.nn.measurements.multiqubit_observable_measurement import get_pauli_multiqubit_observables,get_pauli_words,random_pauli_string_over_meas_wires,measurement_multiqubit\n",
    "from src.nn.measurements.probs_measurement import probs_measurement\n",
    "from src.nn.ansatz.NQ_circuit import NQ_circuit\n",
    "from src.nn.ansatz.ring_circuit import ring_circuit\n",
    "from src.nn.encodings.IQP_embedding import custom_iqp_embedding\n",
    "from src.nn.encodings.NQE_embedding import NQE_embedding\n",
    "from src.nn.encodings.ring_embedding import ring_embedding\n",
    "from src.nn.encodings.waterfall_embedding import waterfall_embedding\n",
    "from src.nn.encodings.pennylane_templates import amplitude_embedding, angle_embedding, QAOA_embedding\n",
    "from src.nn.encodings.frqi_mc import FRQI_MC\n",
    "from src.utils.dataset import EuroSAT, DeepSatCSV\n",
    "from src.utils.reshape_data import ReshapeDATA\n",
    "\n",
    "from src.nn.models.quantum.QCNN import QuantumCircuitModel\n",
    "from src.utils.training import Trainer\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"pennylane\").setLevel(logging.WARNING)\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='IPython')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2731af-3143-4b1c-928c-f386fc904813",
   "metadata": {},
   "source": [
    "## Prueba caso 11 qubits\n",
    "- 1000 limit images\n",
    "- batch\\_size=16\n",
    "- FRQI\n",
    "- 10 clases (caso m√°s demandante)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f88187-e5fe-42bf-ae48-92b18014dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 1000\n",
    "dataset_ = \"EuroSAT\"\n",
    "\n",
    "if dataset_ == \"EuroSAT\":\n",
    "    allowed_classes = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway', 'Industrial', 'Pasture', 'PermanentCrop', 'Residential', 'River', 'SeaLake']\n",
    "elif dataset_ == \"DeepSat4\":\n",
    "    allowed_classes = ['BarrenLand', 'Trees', 'Grassland', 'Other']\n",
    "elif dataset_ == \"DeepSat6\":\n",
    "    allowed_classes = ['BarrenLand', 'Trees', 'Grassland', 'Roads', 'Buildings' , 'WaterBodies']\n",
    "    \n",
    "config = {\n",
    "    # 'allowed_classes': ['Industrial', 'SeaLake']\n",
    "    'allowed_classes': allowed_classes\n",
    "    #'allowed_classes': ['Trees', 'Grassland', 'Other']\n",
    "    #'allowed_classes': ['BarrenLand', 'Grassland', 'Buildings']\n",
    "}\n",
    "\n",
    "allowed_classes = config.get('allowed_classes', allowed_classes)\n",
    "n_classes = len(allowed_classes)\n",
    "\n",
    "image_size = 16\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "if dataset_ == \"EuroSAT\":\n",
    "\n",
    "    output = 'dl'\n",
    "    data = EuroSAT(root= 'dataset/EuroSAT_RGB',\n",
    "                            image_size=image_size,\n",
    "                            examples_per_class=limit,\n",
    "                            batch_size=batch_size,\n",
    "                            allowed_classes=allowed_classes,\n",
    "                            output = output\n",
    "                     )\n",
    "    \n",
    "    if output == 'dl':\n",
    "        train_loader, val_loader = data.get_loaders()\n",
    "    else:\n",
    "        X_train, y_train, X_val, y_val, index_mapping = data.get_loaders()\n",
    "    \n",
    "        X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "        X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "        y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "    \n",
    "        train_dataset = TensorDataset(X_train, y_train) \n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "    \n",
    "        train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle = False)\n",
    "else:\n",
    "    if dataset_ == \"DeepSat4\":\n",
    "        # Root\n",
    "        data_path = \"dataset/DeepSat4/\"\n",
    "        x_train_file = data_path + \"X_train_sat4.csv\"\n",
    "        y_train_file = data_path + \"y_train_sat4.csv\"\n",
    "        x_test_file = data_path + \"X_test_sat4.csv\"\n",
    "        y_test_file = data_path + \"y_test_sat4.csv\"\n",
    "        \n",
    "    elif dataset_ == \"DeepSat6\":\n",
    "        # Root\n",
    "        data_path = \"dataset/DeepSat6/\"\n",
    "        x_train_file = data_path + \"X_train_sat6.csv\"\n",
    "        y_train_file = data_path + \"y_train_sat6.csv\"\n",
    "        x_test_file = data_path + \"X_test_sat6.csv\"\n",
    "        y_test_file = data_path + \"y_test_sat6.csv\"\n",
    "        \n",
    "    # Limit\n",
    "    max_train_samples = limit \n",
    "    max_test_samples = int(0.2 * limit)   \n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_dataset = DeepSatCSV(x_train_file, y_train_file, max_samples=max_train_samples)\n",
    "    test_dataset = DeepSatCSV(x_test_file, y_test_file, max_samples=max_test_samples)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#print(f\"Using device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f6bf94b-f24e-40fd-9811-c963cc92b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = {\n",
    "    'name': 'FRQI_MC',\n",
    "    'func': FRQI_MC,\n",
    "    'func_params': {\n",
    "        'img_pixels': image_size\n",
    "    }\n",
    "}\n",
    "\n",
    "if embedding['name'] == \"FRQI_MC\":\n",
    "    n_wires = np.ceil(np.log2(image_size**2)+3).astype(int)\n",
    "else:\n",
    "    n_wires = np.ceil(np.log2(3*image_size**2)).astype(int)\n",
    "\n",
    "use_quantum = True\n",
    "log = False #graph accuracies in wandb\n",
    "plot = True #plot confusion matrix\n",
    "#name_run = \"one_kernel\"\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf13d79a-8360-4d75-a9ca-036db3a31796",
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_out_wires = [] # qubits that are traced out in pooling layers, skipped in measurement\n",
    "params_obs = {\n",
    "    'meas_wires':[0,4],\n",
    "    'n_obs': n_classes\n",
    "}\n",
    "observables = random_pauli_string_over_meas_wires(range(n_wires),params_obs)\n",
    "\n",
    "measurement = {\n",
    "    'name': 'multiqubit',\n",
    "    'func': measurement_multiqubit,\n",
    "    'func_params': {\n",
    "        'observables': observables\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fadcb2af-1adc-43cf-a9bc-a263139d1543",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = {\n",
    "    # 'name': 'simplified_two_design'\n",
    "    # 'name': 'one_kernel'\n",
    "    # 'name': 'two_kernels',\n",
    "    'name': 'QCNN_multiclass',\n",
    "}\n",
    "\n",
    "if ansatz['name'] == 'one_kernel':\n",
    "    ansatz['func'] = one_kernel\n",
    "    ansatz['func_params'] = {'layers':1}\n",
    "    weight_shapes,_ = get_num_params_one_kernel(range(n_wires),ansatz['func_params'])\n",
    "    \n",
    "elif ansatz['name'] == 'two_kernels':\n",
    "    ansatz['func'] = two_kernels\n",
    "    ansatz['func_params'] = {'layers':1}\n",
    "    weight_shapes,_ = get_num_params_two_kernels(range(n_wires),ansatz['func_params'])\n",
    "    \n",
    "elif ansatz['name'] == 'simplified_two_design':\n",
    "    ansatz['func'] = simplified_two_design\n",
    "    ansatz['func_params'] = {'layers':15}\n",
    "    weight_shapes,_ = get_num_params_simplified_two_design(range(n_wires),ansatz['func_params'])\n",
    "\n",
    "elif ansatz['name'] == 'QCNN_multiclass':\n",
    "    ansatz['func'] = QCNN_multiclass\n",
    "    ansatz['func_params'] = {\n",
    "        # 'layers':1\n",
    "        'dropped_wires':[],\n",
    "        #'excluded_wires':[0,1,2]\n",
    "        }\n",
    "    weight_shapes,_ = get_num_params_QCNN_multiclass(range(n_wires),ansatz['func_params'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf509a5b-b55e-4a62-91cc-06173326898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qcnn = QuantumCircuitModel(n_wires=n_wires,\n",
    "                     embedding=embedding,\n",
    "                     circuit=ansatz,\n",
    "                     measurement=measurement,\n",
    "                     weight_shapes={'weights':weight_shapes},\n",
    "                    #  reshaper=ReshapeDATA(wires=range(n_wires),params={'structure':'flat','img_pixels':image_size})\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f65acc6d-46b4-4d98-a879-2a791a04e50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d09d2bb-ca03-46b4-8c22-92d6e2f73083",
   "metadata": {},
   "outputs": [],
   "source": [
    "qml_device_name = model_qcnn.qdevice_kwargs.pop('qml_device_name', 'default.qubit')\n",
    "model_qcnn.qml_device = qml.device(\n",
    "    qml_device_name, wires=model_qcnn.n_wires, **model_qcnn.qdevice_kwargs\n",
    ")\n",
    "\n",
    "model_qcnn.qnode = qml.QNode(\n",
    "            model_qcnn.quantum_circuit,\n",
    "            model_qcnn.qml_device,\n",
    "            interface='torch',\n",
    "            diff_method='backprop'\n",
    "        )\n",
    "model_qcnn.qlayer = qml.qnn.TorchLayer(model_qcnn.qnode,{'weights':weight_shapes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b8a3482-9288-40ea-abbb-d25af47cdb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "name_prueba = f\"Pruebas QCNN\"\n",
    "\n",
    "trainer_qcnn = Trainer(model = model_qcnn,\n",
    "                  train_loader = train_loader,\n",
    "                  val_loader = val_loader,\n",
    "                  epochs = epochs,\n",
    "                  log = log,\n",
    "                  use_quantum = use_quantum,\n",
    "                  plot = plot,\n",
    "                  allowed_classes = allowed_classes,\n",
    "                  lr = learning_rate,\n",
    "                  use_schedulefree = True)\n",
    "#trainer_qcnn.device = 'cpu'\n",
    "print(trainer_qcnn.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1031c-9221-4bb5-969a-83d37ac9172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:104: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /pytorch/aten/src/ATen/native/Copy.cpp:308.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "trainer_qcnn.fit()\n",
    "t1 = (time.time()-t0)/60\n",
    "print(f\"Tiempo de entrenamiento: {int(t1)} minutos y {int(np.round((t1-int(t1))*60,0))} segundos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b312202-45dc-4ad6-b390-072aa757f40e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
